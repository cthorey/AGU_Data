{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os,re\n",
    "import time,pickle\n",
    "from tqdm import *\n",
    "from os.path import expanduser\n",
    "import sklearn\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AGU conference is hold each year in San Francisco a few weeks before christmas.\n",
    "\n",
    "With nearly 24,000 attendees, AGU Fall Meeting is the largest Earth and space science meeting in the world. As such, it is also a great dataset to study trends in the geoscience community. In the following, I use the papers contribution in the year 2015 and 2014 to find out some hidden structure in the abstracts.\n",
    "The aim is two fold:\n",
    "\n",
    "- For a given contribution, identify a list of similar contribution in the database\n",
    "- For the contributions of a particular authors, identify a list of potential collaborators with names, adress and institute displayed on a map.\n",
    "\n",
    "The method is greatly inspired from [Amir Amini](https://www.kaggle.com/amirhamini/d/benhamner/nips-2015-papers/find-similar-papers-knn/notebook) and [brandonmrose](http://brandonrose.org/clustering)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrapping the AGU website "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scripts used to scrap the [AGU wesbsite](https://fallmeeting.agu.org/2015/) as well as the resulting data are stored on this [repo](https://github.com/cthorey/agu_data) if you want to reproduce the following by yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "home = expanduser('~')\n",
    "os.chdir(os.path.join(home,'Documents','project','agu_data','repo','agu_data'))\n",
    "from Data_Utils import *\n",
    "\n",
    "data = get_all_data('agu2015')\n",
    "sources = [df for df in data if (''.join(df.title) != \"\") and (df.abstract != '')]\n",
    "raw_abstracts = [df.abstract for df in sources]\n",
    "raw_titles = [' '.join(df.title) for df in sources]\n",
    "sessions = [f.session for f in sources]\n",
    "sections = [f.section for f in sources]\n",
    "authors = [', '.join(f.authors.keys()) for f in sources]\n",
    "\n",
    "def first_clean_title(text):\n",
    "    if text.split(' ')[-1] == '(Invited)':\n",
    "        text = ' '.join(text.split(' ')[:-1])\n",
    "    return text\n",
    "\n",
    "def first_clean_abstract(text):\n",
    "    if text.split('\\n')[0].split(' ')[0] =='ePoster':\n",
    "        text = ' '.join(text.split('\\n')[1:])\n",
    "    return text\n",
    "\n",
    "raw_abstracts = map(first_clean_abstract,raw_abstracts)\n",
    "raw_titles = map(first_clean_title,raw_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AGU abstract are short, $\\sim 300$ words and looks like that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The title of this paper is : \n",
      "  Slow Climate Velocities in Mountain Streams Impart Thermal Resistance to Cold-Water Refugia Across the West\n",
      "\n",
      " The corresponding abstract is :\n",
      " Mountain streams provide important headwater refugia for native fish, amphibians, and other cold-water fauna globally. Although the well documented existence of such refugia indicates some level of resistance to ongoing environmental change, stream warming associated with climate change raises questions about their future persistence. Moreover, evidence exists that air temperatures are warming faster at higher elevations, and some stream temperature models predict that cold streams associated with snowmelt hydrologies will be most sensitive to air temperature increases (i.e. high ratio of stream Δ˚C:air Δ˚C). Here, we estimate stream sensitivities to climate forcing using long-term monitoring records from 927 sites across the topographically complex northwestern U.S. Sensitivity values are combined with high-resolution NorWeST stream temperature scenarios (website:\n",
      "http://www.fs.fed.us/rm/boise/AWAE/projects/NorWeST.html\n",
      ") to map climate velocities at 1 kilometer resolution throughout the 450,000 stream kilometers in the regional network. Our results suggest that cold mountain streams are often ‘double buffered’ against the thermal effects of climate change due to low sensitivities (0.3ºC/ºC) and steep gradients, which translated to very slow climate velocities (<0.35 km/decade for streams >3% slope) from 1968-2011 when air temperatures warmed at the rate of 0.2ºC/decade. Alternative scenarios based on aggressive air temperature warming rates (2x historical rates) and higher sensitivity values of cold streams suggests velocities will remain low in mountain streams due to the dominant effects of steep channel slope and strong local temperature gradients. These results reinforce earlier predictions from high-resolution species distribution models that show which watersheds are most likely to host resilient native trout populations across the West later this century (Climate Shield project website:\n",
      "http://www.fs.fed.us/rm/boise/AWAE/projects/ClimateShield.html\n",
      "). Although other aspects of climate change related to changing hydrology and disturbance regimes may affect stream refuges in mountainous areas, their high thermal resistance should enable many to continue serving as conservatoires of cold-water biodiversity for the foreseeable future.\n"
     ]
    }
   ],
   "source": [
    "idx = 300\n",
    "print '\\n The title of this paper is : \\n %s'%(raw_titles[idx])\n",
    "print '\\n The corresponding abstract is :\\n %s'%(raw_abstracts[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first remove extra text in the abstract (eposter) and (Invited) + convert unicode characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "\n",
    "def clean(text):\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii','ignore')\n",
    "    text = text.replace('\\n', ' ')\n",
    "    return text\n",
    "\n",
    "titles = map(clean,raw_titles)\n",
    "abstracts = map(clean,raw_abstracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The title of this paper is : \n",
      "  Slow Climate Velocities in Mountain Streams Impart Thermal Resistance to Cold-Water Refugia Across the West\n",
      "\n",
      " The corresponding abstract is :\n",
      " Mountain streams provide important headwater refugia for native fish, amphibians, and other cold-water fauna globally. Although the well documented existence of such refugia indicates some level of resistance to ongoing environmental change, stream warming associated with climate change raises questions about their future persistence. Moreover, evidence exists that air temperatures are warming faster at higher elevations, and some stream temperature models predict that cold streams associated with snowmelt hydrologies will be most sensitive to air temperature increases (i.e. high ratio of stream  C:air  C). Here, we estimate stream sensitivities to climate forcing using long-term monitoring records from 927 sites across the topographically complex northwestern U.S. Sensitivity values are combined with high-resolution NorWeST stream temperature scenarios (website: http://www.fs.fed.us/rm/boise/AWAE/projects/NorWeST.html ) to map climate velocities at 1 kilometer resolution throughout the 450,000 stream kilometers in the regional network. Our results suggest that cold mountain streams are often double buffered against the thermal effects of climate change due to low sensitivities (0.3oC/oC) and steep gradients, which translated to very slow climate velocities (<0.35 km/decade for streams >3% slope) from 1968-2011 when air temperatures warmed at the rate of 0.2oC/decade. Alternative scenarios based on aggressive air temperature warming rates (2x historical rates) and higher sensitivity values of cold streams suggests velocities will remain low in mountain streams due to the dominant effects of steep channel slope and strong local temperature gradients. These results reinforce earlier predictions from high-resolution species distribution models that show which watersheds are most likely to host resilient native trout populations across the West later this century (Climate Shield project website: http://www.fs.fed.us/rm/boise/AWAE/projects/ClimateShield.html ). Although other aspects of climate change related to changing hydrology and disturbance regimes may affect stream refuges in mountainous areas, their high thermal resistance should enable many to continue serving as conservatoires of cold-water biodiversity for the foreseeable future.\n"
     ]
    }
   ],
   "source": [
    "idx = 300\n",
    "print '\\n The title of this paper is : \\n %s'%(titles[idx])\n",
    "print '\\n The corresponding abstract is :\\n %s'%(abstracts[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing and stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The texts above cannot be fed directly into an algorithm to identify pattern within the corpus.\n",
    "Instead, some form of vectorization have to be used.\n",
    "\n",
    "A bag of words method is generally used in that purpose. In such a method, each document is first broken into unbreakable tokens and, in this method:\n",
    "\n",
    "- each individual token occurrence frequency (normalized or not) is treated as a feature.\n",
    "- the vector of all the token frequencies for a given document is considered a multivariate sample.\n",
    "\n",
    "In the following, I build a function based on the library **nltk** to broke a documents into its most basic form, a list of stems.\n",
    "\n",
    "To do so, \n",
    "\n",
    "- We first broke each documents in sentence and the words\n",
    "- Remove all numeric, ponctuations with the module **re**\n",
    "- Remove stowords from the tokens\n",
    "- Stem each resulting tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "# Load SnowballStemmer as variabled 'stemmer'\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "# load nltk's English stopwords as variable called 'stopwords'\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def tokenize_and_stem(text):\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token.lower())\n",
    "    filtered_tokens = [token for token in filtered_tokens if token not in stopwords]\n",
    "    stems = map(stemmer.stem,filtered_tokens)\n",
    "    return map(str,stems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf-idf representation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the **tokenize_and_stem** function, we can then break each document in tokens and vectorize it. The vectorization will result in a matrix whom \n",
    "\n",
    "- each line is a text document of the corpus\n",
    "- each column represent a token from the corpus\n",
    "- a specific value represent the number of occurences of a particular token in a particular document\n",
    "\n",
    "While **sklearn** provides a class **CountVectorizer** which can be used to form such a matrix, this representation often put to much weights on common words of the corpus, i.e. words like *the*, *a* in english. While this can be interesting in some situations, we would like to put more weight on words that make each abstract specific for our application.\n",
    "\n",
    "One way to do this is to use a **Tf-idf** normalization to re-weiht each value in the matrix by the frequency of the token in the whole corpus. **Tf** means term-frequency while **tf–idf** means term-frequency times inverse document-frequency.\n",
    "\n",
    "This normalization is implemented by the **TfidfTransformer** class of sklearn and is used in the following.\n",
    "\n",
    "Main parameters:\n",
    "\n",
    "- max_df : When building the vocabulary ignore terms that have a document frequency strictly higher than the given threshold\n",
    "- min_df : When building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold\n",
    "- ngram_range : Range of n-gram to consider. Bi-gram and Three gram like floor fractured craters is preserved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small sub-routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Small routine to save the idf class and the resulting matrix.\n",
    "model_saved = os.path.join(home,'Documents','project','agu_data','repo','Notebook','Models')\n",
    "from sklearn.externals import joblib\n",
    "def save_idf(folder,idf_vectorizer,idf_matrix):\n",
    "    joblib.dump(idf_vectorizer,os.path.join(folder,'idf_vectorizer.pkl'))\n",
    "    joblib.dump(idf_matrix,os.path.join(folder,'idf_matrix.pkl'))\n",
    "    \n",
    "def open_idf(folder):\n",
    "    idf_vectorizer = joblib.load(os.path.join(folder,'idf_vectorizer.pkl'))\n",
    "    idf_matrix = joblib.load(os.path.join(folder,'idf_matrix.pkl'))\n",
    "    return idf_vectorizer, idf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load files\n",
      "CPU times: user 1.91 s, sys: 73.9 ms, total: 1.98 s\n",
      "Wall time: 2.18 s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "folder_titles = os.path.join(model_saved,'tfidf','titles')\n",
    "recompute = False\n",
    "if len(os.listdir(folder_titles)) == 0 or recompute:\n",
    "    print 'Create files'\n",
    "    titles_tfidf_vectorizer = TfidfVectorizer(analyzer = 'word',\n",
    "                                   max_df=0.95, \n",
    "                                   max_features=200000, \n",
    "                                   min_df=0.001, \n",
    "                                   stop_words=stopwords,\n",
    "                                   use_idf=True, \n",
    "                                   tokenizer=tokenize_and_stem,\n",
    "                                   lowercase = True,\n",
    "                                   ngram_range=(1,3))\n",
    "    %time idf_titles = titles_tfidf_vectorizer.fit_transform(titles)\n",
    "    save_idf(folder_titles,titles_tfidf_vectorizer,idf_titles)\n",
    "else:\n",
    "    print 'Load files'\n",
    "    %time titles_tfidf_vectorizer, idf_titles = open_idf(folder_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstracts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create files\n",
      "CPU times: user 5min 10s, sys: 6.19 s, total: 5min 16s\n",
      "Wall time: 5min 33s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "folder_abstracts = os.path.join(model_saved,'tfidf','abstracts')\n",
    "\n",
    "recompute = True\n",
    "if len(os.listdir(folder_titles)) == 0 or recompute:\n",
    "    print 'Create files'\n",
    "    abstracts_tfidf_vectorizer = TfidfVectorizer(analyzer = 'word',\n",
    "                                   max_df=0.9, \n",
    "                                   max_features=200000, \n",
    "                                   min_df=0.01, \n",
    "                                   stop_words=stopwords,\n",
    "                                   use_idf=True, \n",
    "                                   tokenizer=tokenize_and_stem,\n",
    "                                   lowercase = True,\n",
    "                                   ngram_range=(1,3))\n",
    "    %time idf_abstracts = abstracts_tfidf_vectorizer.fit_transform(abstracts)\n",
    "    save_idf(folder_abstracts,abstracts_tfidf_vectorizer,idf_abstracts)\n",
    "else:\n",
    "    print 'Load files'\n",
    "    %time abstracts_tfidf_vectorizer, idf_abstracts = open_idf(folder_abstracts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making sense of the tf-idf resulting arrays "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def top_tfidf_feats(row, features, top_n=25):\n",
    "    ''' Get top n tfidf values in row and return \n",
    "        them with their corresponding feature names.'''\n",
    "    \n",
    "    topn_ids = np.argsort(row)[::-1][:top_n]\n",
    "    top_feats = [(features[i], row[i]) for i in topn_ids]\n",
    "    df = pd.DataFrame(top_feats)\n",
    "    df.columns = ['feature', 'tfidf']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>intrus</td>\n",
       "      <td>0.595818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>deform</td>\n",
       "      <td>0.223510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>magmat</td>\n",
       "      <td>0.204524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>regim</td>\n",
       "      <td>0.180677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>predict</td>\n",
       "      <td>0.167379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature     tfidf\n",
       "0   intrus  0.595818\n",
       "1   deform  0.223510\n",
       "2   magmat  0.204524\n",
       "3    regim  0.180677\n",
       "4  predict  0.167379"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 6339\n",
    "top_tfidf_feats(np.squeeze(idf_abstracts[idx].toarray()),abstracts_tfidf_vectorizer.get_feature_names(),5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>general</td>\n",
       "      <td>0.538683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>intrus</td>\n",
       "      <td>0.511470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>magmat</td>\n",
       "      <td>0.465001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shallow</td>\n",
       "      <td>0.427042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>model</td>\n",
       "      <td>0.222773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature     tfidf\n",
       "0  general  0.538683\n",
       "1   intrus  0.511470\n",
       "2   magmat  0.465001\n",
       "3  shallow  0.427042\n",
       "4    model  0.222773"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 6339\n",
    "top_tfidf_feats(np.squeeze(idf_titles[idx].toarray()),titles_tfidf_vectorizer.get_feature_names(),5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding similar document based on the abstracts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine similarities "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tf-idf representation provides a high-dimensionlal embedding of each paper in the corpus. From there, the baseline method is to use directly this representation to compute similiarites between different abstract. This is the so-called [Vector Space Model](https://en.wikipedia.org/wiki/Vector_space_model).\n",
    "\n",
    "Indeed, in the tf-df representation, each paper represents a vector in a high dimensional space. The *distance* or the *similarity*, according to some metrics, can then be used to compare different contributions together. \n",
    "\n",
    "The euclidean distance is the more natural choise for the similarity measure. Given two vectors  $\\vec{a}$ and $\\vec{b}$, it is equal to \n",
    "$$d(\\vec{a},\\vec{b}) = \\sqrt{(\\vec{b}- \\vec{a})\\cdot(\\vec{b}- \\vec{a}) }$$\n",
    "\n",
    "\n",
    "However, we'd like our distance to be independant of the magnitude of the difference between two vectors. For instance, we'd like to identify as similar two documents which contain exactly the same words even if the word occurences differ significantly. The euclidean distance clearly does not have this property.\n",
    "\n",
    "Accordingly, a more reliable measure for our purpose is called \"the cosine similarity\". For two vectors, $\\vec{a}$ and $\\vec{b}$, the cosine similarity $d$ is defined as :\n",
    "\n",
    "$$ d(\\vec{a},\\vec{b})= \\frac{\\vec{a} \\cdot \\vec{b}}{|\\vec{a}||\\vec{b}|} = \\cos(\\vec{a},\\vec{b})$$\n",
    "\n",
    "In particular, this similarity measure is the dot product of the two normalized vector and hence, depends only on the angle between the two vectors (which is were its name comes from ;)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The good thing with our tf-idf representation is that each row, i.e. each abstract, is already normalized. Therefore, computing the similarity between two abstracts can be done by a simple dot product between the two corresponding rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_recommendation(vrepr,tfidf_matrix,top_n):\n",
    "    ''' Return the similarity as well as the index of the top_n abstracts for one contribution\n",
    "    \n",
    "    Args:\n",
    "        vrepr:  vector represenatation of the contribution you want to look at\n",
    "        tfidf_matrix: tf-idf matrix for the corpus\n",
    "        top_n: Number of similar contribution you want to retreive\n",
    "    \n",
    "    Returns:\n",
    "        Similarity score and index of the top_n closest abstract\n",
    "    '''\n",
    "    score = np.squeeze(np.dot(tfidf_matrix.toarray(),vrepr.T))\n",
    "    score_idx = np.argsort(score)[::-1]\n",
    "    return score[score_idx[:top_n]],score_idx[:top_n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try our method on my AGU contribution this year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def name_to_idx(name):\n",
    "    ''' From an authors, return the list of contributions '''\n",
    "    contrib = [f for f in sources if name in f.authors.keys()]\n",
    "    return [sources.index(elt) for elt in contrib]\n",
    "    \n",
    "my_contrib = name_to_idx('Clement Thorey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 0 contrib is:  A General Model for Shallow Magmatic Intrusions\n",
      "Rank 1 contrib is:  Periodicity of Kı̄lauea’s Dike Intrusions\n",
      "Rank 2 contrib is:  Floor-Fractured Craters through Machine Learning Methods\n",
      "Rank 3 contrib is:  Geophysical Survey and Detailed Geologic Mapping of an Eroded Stratovolcano’s Central Intrusive Complex, Summer Coon, Co.\n",
      "Rank 4 contrib is:  Geophysical Interpretation of Mantle Magmatism in the Seiland Province\n",
      "Rank 5 contrib is:  The Sills of Guaymas Basin, Gulf of California\n",
      "Rank 6 contrib is:  Monitoring and Assessment of Saltwater Intrusion using Geographic Information Systems (GIS), Remote Sensing and Geophysical measurements of Guimaras Island, Philippines\n",
      "Rank 7 contrib is:  Stable Isotope Variability of Altered Sanidine Feldspars within the Bear Lodge Alkaline Intrusive Complex, Wyoming\n",
      "Rank 8 contrib is:  New Insights into the 2009 Harrat Lunayyir Dike Intrusion from InSAR, Stress Calculations and Analog Experiments\n",
      "Rank 9 contrib is:  Dating Intrusions in the Salinian Block Using Single Zircon U-PB CA-TIMS Analysis\n"
     ]
    }
   ],
   "source": [
    "idf_matrix = idf_abstracts\n",
    "vrepr = idf_matrix[my_contrib[1],:].toarray()\n",
    "similarities, indexs = find_recommendation(vrepr, idf_matrix, 10)\n",
    "recoms = np.array(sources)[indexs]\n",
    "for i, elt in enumerate(recoms):\n",
    "    print 'Rank %d contrib is: %s'%(i,elt.title[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without getting into the details, this abstract was about the dynamics of magmatic intrusions, batches of magma that stall at shallow depth into the Earth crust. Look's like our vanilla algorithm makes a pretty good job! I have actually been to most of the 25 recommendations this year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of looking at a specific contribution, we can also just throw in some keywords. The only additional step in that case is to transform our request into the vector space before giving it to the **find_recommenation** function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 0 contrib is:  Integrating Scientific Inquiry into an Undergraduate Applied Remote Sensing Course\n",
      "Rank 1 contrib is:  The World Climate Exercise\n",
      "Rank 2 contrib is:  Learning and Risk Exposure in a Changing Climate (Invited)\n",
      "Rank 3 contrib is:  Online Experiential Learning\n",
      "Rank 4 contrib is:  Blue Sky Funders Forum - Advancing Environmental Literacy through Funder Collaboration (Invited)\n",
      "Rank 5 contrib is:  Promoting Physical Understanding through Peer Mentoring\n",
      "Rank 6 contrib is:  Place in Pacific Islands Climate Education\n",
      "Rank 7 contrib is:  Evolution of Evaluation and Assessment in Diverse Audiences in the Digital Age (Invited)\n",
      "Rank 8 contrib is:  Field Learning as a powerful tool of Education for geoscience, environment and disaster prevention.\n",
      "Rank 9 contrib is:  Harnessing the power of mobile technologies for collaborating, crowdsourcing, and creating (Invited)\n"
     ]
    }
   ],
   "source": [
    "request = ['machine learning']\n",
    "vrepr = abstracts_tfidf_vectorizer.transform(request).toarray()\n",
    "idf_matrix = idf_abstracts\n",
    "similarities, indexs = find_recommendation(vrepr, idf_matrix, 10)\n",
    "recoms = np.array(sources)[indexs]\n",
    "for i, elt in enumerate(recoms):\n",
    "    print 'Rank %d contrib is: %s'%(i,elt.title[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example is less convincing. The return proposition are actually focused on learning but none exhibit machine learning thematic as expected by the request. This is actually expected as these recommendation are based on the abstract itself. Machine learning keywords in geoscience conference like AGU are more likely to be diluted in the application itself within the abstract. We should have more luck on a title-based recommendation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 0 contrib is:  Floor-Fractured Craters through Machine Learning Methods\n",
      "Rank 1 contrib is:  Machine Learning for Flood Prediction in Google Earth Engine\n",
      "Rank 2 contrib is:  Machine Learning in Ionospheric Phenomena Detection Using Passive Radar\n",
      "Rank 3 contrib is:  CME Prediction Using SDO, SoHO, and STEREO data with a Machine Learning Algorithm\n",
      "Rank 4 contrib is:  A Data-Driven Approach to Assess Coastal Vulnerability\n",
      "Rank 5 contrib is:  Near-Surface Crevasse Detection in Ice Sheets using Feature-Based Machine Learning\n",
      "Rank 6 contrib is:  Applying Machine Learning Tools to the Identification of Foreshock Transient Events\n",
      "Rank 7 contrib is:  Machine Learning to Assess Grassland Productivity in Southeastern Arizona\n",
      "Rank 8 contrib is:  Temporal Mixture Analysis of Hypertemporal Antarctic Sea Ice Data in the Sense of Machine Learning\n",
      "Rank 9 contrib is:  Using Machine learning method to estimate Air Temperature from MODIS over Berlin\n"
     ]
    }
   ],
   "source": [
    "request = ['machine learning']\n",
    "vrepr = titles_tfidf_vectorizer.transform(request).toarray()\n",
    "idf_matrix = idf_titles\n",
    "similarities, indexs = find_recommendation(vrepr, idf_matrix, 10)\n",
    "recoms = np.array(sources)[indexs]\n",
    "for i, elt in enumerate(recoms):\n",
    "    print 'Rank %d contrib is: %s'%(i,elt.title[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here they are ;)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Difference between the abstract based and the titles based recommendations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about the contribution-recommendations based on the titles only ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 0 contrib is:  A General Model for Shallow Magmatic Intrusions\n",
      "Rank 1 contrib is:  A generalized quasi-geostrophic model of thermal convection (Invited)\n",
      "Rank 2 contrib is:  Characteristics of Earthquakes Induced by Shallow and Deep Crustal Dike Intrusions\n",
      "Rank 3 contrib is:  Modeling of Magnetic Anomalies Associated with Magmatic Intrusions Away from the Guaymas Basin Rift, Gulf of California\n",
      "Rank 4 contrib is:  Periodicity of Kı̄lauea’s Dike Intrusions\n",
      "Rank 5 contrib is:  How to build a mid-crustal intrusive suite\n",
      "Rank 6 contrib is:  Petrological evidence for non-linear increase of magmatic intrusion rates before eruption at open vent mafic volcanoe\n",
      "Rank 7 contrib is:  Interactive Modelling of Salinity Intrusion in the Rhine-Meuse Delta\n",
      "Rank 8 contrib is:  Modeling Saltwater Intrusion in Highly Heterogeneous Coastal Aquifers\n",
      "Rank 9 contrib is:  Yingmailai Granitic Intrusion in the Southern Tianshan：Magnetite-series or Ilmenite-series?\n"
     ]
    }
   ],
   "source": [
    "idf_matrix = idf_titles\n",
    "vrepr = idf_matrix[my_contrib[1],:].toarray()\n",
    "similarities, indexs = find_recommendation(vrepr, idf_matrix, 10)\n",
    "recoms = np.array(sources)[indexs]\n",
    "for i, elt in enumerate(recoms):\n",
    "    print 'Rank %d contrib is: %s'%(i,elt.title[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the recommendations is not exactly the same. Indeed, the information retrieval from only the tile is a more random task than based on the larger abstract content. Based-title recommendantion highly depends on the title content. \n",
    "\n",
    "For instance, my second contribution to AGU was about the detection of floor-fractured craters through machine learning method. While the abstract of this contribution is more planetology (cratering stuff) related, I wanted *machine learning* to appear in the title for encouraging people in the machine learning community to stop by and talk about the algorithm I used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendantion tittle-based\n",
      "Rank 0 contrib is:  Floor-Fractured Craters through Machine Learning Methods\n",
      "Rank 1 contrib is:  Using Machine learning method to estimate Air Temperature from MODIS over Berlin\n",
      "Rank 2 contrib is:  Machine Learning for Flood Prediction in Google Earth Engine\n",
      "Rank 3 contrib is:  Machine Learning in Ionospheric Phenomena Detection Using Passive Radar\n",
      "Rank 4 contrib is:  CME Prediction Using SDO, SoHO, and STEREO data with a Machine Learning Algorithm\n",
      "Rank 5 contrib is:  A Data-Driven Approach to Assess Coastal Vulnerability\n",
      "Rank 6 contrib is:  Near-Surface Crevasse Detection in Ice Sheets using Feature-Based Machine Learning\n",
      "Rank 7 contrib is:  Applying Machine Learning Tools to the Identification of Foreshock Transient Events\n",
      "Rank 8 contrib is:  Machine Learning to Assess Grassland Productivity in Southeastern Arizona\n",
      "Rank 9 contrib is:  Temporal Mixture Analysis of Hypertemporal Antarctic Sea Ice Data in the Sense of Machine Learning\n",
      "\n",
      "\n",
      "Recommendantion abstract-based\n",
      "Rank 0 contrib is:  Floor-Fractured Craters through Machine Learning Methods\n",
      "Rank 1 contrib is:  The collisional history of dwarf planet Ceres revealed by Dawn\n",
      "Rank 2 contrib is:  Katabatically Driven Downslope Windstorm-Type Flows on the Inner Sidewall of Arizona's Barringer Meteorite Crater (Invited)\n",
      "Rank 3 contrib is:  Preliminary Geological Map of the Ac-H-2 Coniraya Quadrangle of Ceres\n",
      "Rank 4 contrib is:  Morphologic Analysis of Lunar Craters in the Simple-to-Complex Transition\n",
      "Rank 5 contrib is:  Structural and Geological Interpretation of Posidonius Crater on the Moon\n",
      "Rank 6 contrib is:  An Ice-rich Mantle on Ceres from Dawn Mapping of Central Pit and Peak Crater Morphologies\n",
      "Rank 7 contrib is:  Initial Results from a Global Database of Mercurian Craters\n",
      "Rank 8 contrib is:  Lunar Crater Interiors with High Circular Polarization Signatures\n",
      "Rank 9 contrib is:  Comparing Radar and Optical Data Sets of Lunar Impact Crater Ejecta\n"
     ]
    }
   ],
   "source": [
    "idf_matrix = idf_titles\n",
    "vrepr = idf_matrix[my_contrib[0],:].toarray()\n",
    "similarities, indexs = find_recommendation(vrepr, idf_matrix, 10)\n",
    "recoms = np.array(sources)[indexs]\n",
    "print 'Recommendantion tittle-based'\n",
    "for i, elt in enumerate(recoms):\n",
    "    print 'Rank %d contrib is: %s'%(i,elt.title[0])\n",
    "    \n",
    "idf_matrix = idf_abstracts\n",
    "vrepr = idf_matrix[my_contrib[0],:].toarray()\n",
    "similarities, indexs = find_recommendation(vrepr, idf_matrix, 10)\n",
    "recoms = np.array(sources)[indexs]\n",
    "print '\\n\\nRecommendantion abstract-based'\n",
    "for i, elt in enumerate(recoms):\n",
    "    print 'Rank %d contrib is: %s'%(i,elt.title[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the recommendations favor machine learning abstract based on the title only and planetology related topics when looking at the abstract. While it could be possible to combine both approach, I found the results complementary and decided not to go further at this point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Sklearn** implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sklearn** actaully implemented a class NearestNeighboor which ingest the tf-idf based matrix and is able to return the closest neightboor according to a whole bunch of difference distance metrics. While, our function designed above looks pretty fast, I assumed their implementation is more complete and I'll use it in the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def print_result(recom, verbose):\n",
    "    ''' Detail printing of the recommendation \n",
    "    \n",
    "    Args:\n",
    "        recom : Dataframe of the recommendation\n",
    "        verbose: Degree of verbosity\n",
    "            - 0: no printing\n",
    "            - 1: print the titles\n",
    "            - >1: print the authors and the abstracts\n",
    "            - >2: print more than 2 recommendations\n",
    "    '''\n",
    "    for i, row in recom.iterrows():\n",
    "        if verbose <3:\n",
    "            if i>2:\n",
    "                break\n",
    "        if i == 0:\n",
    "            if verbose>0:\n",
    "                print 'The recommendation is based on the contribution: %s \\n'%(row.title)\n",
    "            if verbose >1:\n",
    "                print 'of %s\\n'%(row.authors)\n",
    "                print 'The abstract is: \\n \\n%s \\n\\n'%(row.abstract)\n",
    "        else:\n",
    "            if verbose >0:\n",
    "                print 'The recommendation number %d is: %s\\n'%(i,row.title)\n",
    "            if verbose >1:\n",
    "                print 'of %s\\n'%(row.authors)\n",
    "                print 'The abstract is: \\n \\n%s \\n\\n'%(row.abstract)\n",
    "        \n",
    "\n",
    "def idx_to_recom(index, n_neightboor = 20, based_on ='abstracts', verbose = 0):\n",
    "    ''' Return a list of recommendation for the corresponding index\n",
    "    \n",
    "    Args:\n",
    "        index : index of the contribution to look at\n",
    "        n_neightboor : Number of neightboor to return\n",
    "        based_on : Base the recommendation on the abstract or the titles ?\n",
    "        verbose : Degree of verbosity for the return\n",
    "        \n",
    "    Returns:\n",
    "        A size n_neightboor dataframe of the recommendation\n",
    "        \n",
    "    '''\n",
    "    base = {'abstracts': idf_abstracts, 'titles': idf_titles}\n",
    "    nearest = NearestNeighbors(n_neighbors=200,\n",
    "                               algorithm='brute',\n",
    "                               metric = 'cosine')\n",
    "    \n",
    "    idf_matrix = base[based_on]\n",
    "    nearest.fit(idf_matrix)\n",
    "    distances ,indices = nearest.kneighbors(X = idf_matrix[index],\n",
    "                                            n_neighbors = n_neightboor,\n",
    "                                            return_distance=True)\n",
    "    recom_index = indices[0,:]\n",
    "    recom = np.vstack((range(len(recom_index)),\n",
    "                       np.array(raw_titles)[recom_index],\n",
    "                       np.array(raw_abstracts)[recom_index],\n",
    "                       np.array(sections)[recom_index],\n",
    "                       np.array(sessions)[recom_index],\n",
    "                       np.array(authors)[recom_index],\n",
    "                      ))\n",
    "    recom = pd.DataFrame(recom.T,columns = ['Order','title','abstract','section','session','authors'])\n",
    "    print_result(recom, verbose)\n",
    "    return recom\n",
    "\n",
    "def request_to_recom(request, n_neightboor = 20, based_on ='abstracts', verbose = 0):\n",
    "    ''' Return a list of recommendation for the corresponding index\n",
    "    \n",
    "    Args:\n",
    "        index : index of the contribution to look at\n",
    "        n_neightboor : Number of neightboor to return\n",
    "        based_on : Base the recommendation on the abstract or the titles ?\n",
    "        verbose : Degree of verbosity for the return\n",
    "        \n",
    "    Returns:\n",
    "        A size n_neightboor dataframe of the recommendation\n",
    "        \n",
    "    '''\n",
    "    base_idf = {'abstracts': idf_abstracts,\n",
    "                'titles': idf_titles}\n",
    "    base_vect = {'abstracts': abstracts_tfidf_vectorizer,\n",
    "                 'titles': titles_tfidf_vectorizer}\n",
    "    \n",
    "    nearest = NearestNeighbors(n_neighbors=200,\n",
    "                               algorithm='brute',\n",
    "                               metric = 'cosine')\n",
    "    \n",
    "    idf_matrix = base_idf[based_on]\n",
    "    nearest.fit(idf_matrix)\n",
    "    distances ,indices = nearest.kneighbors(X = base_vect[based_on].transform(request),\n",
    "                                            n_neighbors = n_neightboor,\n",
    "                                            return_distance=True)\n",
    "    recom_index = indices[0,:]\n",
    "    recom = np.vstack((range(len(recom_index)),\n",
    "                       np.array(raw_titles)[recom_index],\n",
    "                       np.array(raw_abstracts)[recom_index],\n",
    "                       np.array(sections)[recom_index],\n",
    "                       np.array(sessions)[recom_index],\n",
    "                       np.array(authors)[recom_index],\n",
    "                      ))\n",
    "    recom = pd.DataFrame(recom.T,columns = ['Order','title','abstract','section','session','authors'])\n",
    "    print_result(recom, verbose)\n",
    "    return recom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The recommendation is based on the contribution:  Integrating Scientific Inquiry into an Undergraduate Applied Remote Sensing Course \n",
      "\n",
      "The recommendation number 1 is:  The World Climate Exercise  Is (Simulated) Experience Our Best Teacher?\n",
      "\n",
      "The recommendation number 2 is:  Learning and Risk Exposure in a Changing Climate\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recom = request_to_recom(['machine learning'],5,verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More convoluted recommendation system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indentify similarities using the tf-idf representation and the cosine measure is the baseline implementation for **information retrieval**. \n",
    "\n",
    "However, this method is know to have some drawback. On of the main drawback is that measuring distances directly under such a representation may not be reliable since it is a known fact that in very high dimensions, distance between any two points starts to look the same. \n",
    "\n",
    "One way to deal with this is to reduce the data dimensionality using Latent Semantic Analysis; also known as Latent Semantic Indexing) and then measure the distances in the new space. Using something like LSA over PCA is advantageous since it can give a meaningful representation in terms of \"semantic concepts\", apart from measuring distances in a lower dimensional space.\n",
    "\n",
    "Comparing documents based on the probability distributions is usually done by first computing the topic distribution of each document (using something like Latent Dirichlet Allocation), and then computing some sort of divergence (e.g., KL divergence) between the topic distributions of pair of documents. In a way, it's actually kind of similar to doing LSA first and then measuring distances in the LSA space using KL-divergence between the vectors (instead of cosine similarity).\n",
    "\n",
    "KL-divergence is a distance measure for comparing distributions so it may be preferable if the document representation is in terms of some distribution (which is often actually the case -- e.g., documents represented as distribution over topics, as in LDA). Also note that under such a representation, the entries in the feature vector would sum to one (since you are basically treating the document as a distribution over topics or semantic concepts)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application: Identify a list of potential collaborators "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def idx_to_collaborators(index, n_neightboor = 20, based_on ='abstracts', verbose =0):\n",
    "    ''' Return a list of potential collaborator for the corresponding index\n",
    "    \n",
    "    Args:\n",
    "        index : index of the contribution to look at.\n",
    "        n_neightboor : Number of recommendations to consider.\n",
    "        based_on : Base the recommendation on the abstract or the titles ?\n",
    "        verbose : Degree of verbosity for the return.\n",
    "        \n",
    "    Returns:\n",
    "        A list of potential authors that work in similar topic.\n",
    "        \n",
    "    '''\n",
    "    recom = idx_to_recom(index, n_neightboor , based_on,verbose)\n",
    "    auths = [f.strip() for f in reduce(lambda x,y:x+','+y,list(recom.authors)).split(',')]\n",
    "    return auths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
