{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import dryscrape,time,os\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "root = '/Users/thorey/Documents/MLearning/Side_Project/AGU_Data/'\n",
    "os.chdir(root)\n",
    "import time,json\n",
    "from tqdm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "root = '/Users/thorey/Documents/MLearning/Side_Project/AGU_Data/'\n",
    "pathdata = os.path.join(root,'Data')\n",
    "papers_list = [f for f in os.listdir(pathdata) if f.split('_')[0]=='agu2015']\n",
    "papers = []\n",
    "errors = []\n",
    "for i in tqdm(range(len(papers_list))):\n",
    "    name = papers_list[i]\n",
    "    with open(os.path.join(pathdata,name), 'rb') as f:\n",
    "        idxs = pickle.load(f)\n",
    "        papers += idxs['papers']\n",
    "        errors += idxs['error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json,codecs\n",
    "name = os.path.join(root,'Data','agu2015','60180_61180.json')\n",
    "with codecs.open(name, 'r','utg') as f:\n",
    "    idxs = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unicode"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(idxs['papers'].keys()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from LoadData import *\n",
    "from Data_Utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name = os.path.join(root,'Data','agu2015','60180_61180.json')\n",
    "papers = [Paper(key,val) for key,val in load_json(name)['papers'].iteritems()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from Data_Utils import *\n",
    "papers = get_all_data('agu2015')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "authors = [f.authors for f in papers]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'Authors',\n",
       " u'Philip Valek',\n",
       " u'University of Texas at San Antonio',\n",
       " u'Southwest Research Institute',\n",
       " u'Natalia Buzulukova',\n",
       " u'NASA Goddard Space Flight Center',\n",
       " u'Mei-Ching Fok',\n",
       " u'NASA Goddard Space Flight Center',\n",
       " u'Jerry Goldstein',\n",
       " u'Southwest Research Institute',\n",
       " u'Amy Keesee',\n",
       " u'West Virginia University',\n",
       " u'David McComas',\n",
       " u'Southwest Research Institute',\n",
       " u'Joseph Perez',\n",
       " u'Auburn University']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authors[0].split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name NERTagger",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-b9f563ac4065>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstanford\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNERTagger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: cannot import name NERTagger"
     ]
    }
   ],
   "source": [
    "from nltk.tag.stanford import NERTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name NERTagger",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-b9f563ac4065>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstanford\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNERTagger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: cannot import name NERTagger"
     ]
    }
   ],
   "source": [
    "from nltk.tag.stanford import NERTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tag.stanford import StanfordNERTagger as NERTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "standner = '/Users/thorey/Documents/Tool/standfordParser/stanford-ner-2014-08-27'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.chdir(standner)\n",
    "english_nertagger = NERTagger('classifiers/english.all.3class.distsim.crf.ser.gz', 'stanford-ner.jar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokens = nltk.tokenize.word_tokenize(text)\n",
    "pos = nltk.pos_tag(tokens)\n",
    "sentt = nltk.ne_chunk(pos, binary = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Authors', 'NNS'),\n",
       " (u',', ','),\n",
       " (u'Philip', 'NNP'),\n",
       " (u'Valek', 'NNP'),\n",
       " (u',', ','),\n",
       " (u'University', 'NNP'),\n",
       " (u'of', 'IN'),\n",
       " (u'Texas', 'NNP'),\n",
       " (u'at', 'IN'),\n",
       " (u'San', 'NNP'),\n",
       " (u'Antonio', 'NNP'),\n",
       " (u',', ','),\n",
       " (u'Southwest', 'NNP'),\n",
       " (u'Research', 'NNP'),\n",
       " (u'Institute', 'NNP'),\n",
       " (u',', ','),\n",
       " (u'Natalia', 'NNP'),\n",
       " (u'Buzulukova', 'NNP'),\n",
       " (u',', ','),\n",
       " (u'NASA', 'NNP'),\n",
       " (u'Goddard', 'NNP'),\n",
       " (u'Space', 'NNP'),\n",
       " (u'Flight', 'NNP'),\n",
       " (u'Center', 'NNP'),\n",
       " (u',', ','),\n",
       " (u'Mei-Ching', 'JJ'),\n",
       " (u'Fok', 'NNP'),\n",
       " (u',', ','),\n",
       " (u'NASA', 'NNP'),\n",
       " (u'Goddard', 'NNP'),\n",
       " (u'Space', 'NNP'),\n",
       " (u'Flight', 'NNP'),\n",
       " (u'Center', 'NNP'),\n",
       " (u',', ','),\n",
       " (u'Jerry', 'NNP'),\n",
       " (u'Goldstein', 'NNP'),\n",
       " (u',', ','),\n",
       " (u'Southwest', 'NNP'),\n",
       " (u'Research', 'NNP'),\n",
       " (u'Institute', 'NNP'),\n",
       " (u',', ','),\n",
       " (u'Amy', 'NNP'),\n",
       " (u'Keesee', 'NNP'),\n",
       " (u',', ','),\n",
       " (u'West', 'NNP'),\n",
       " (u'Virginia', 'NNP'),\n",
       " (u'University', 'NNP'),\n",
       " (u',', ','),\n",
       " (u'David', 'NNP'),\n",
       " (u'McComas', 'NNP'),\n",
       " (u',', ','),\n",
       " (u'Southwest', 'NNP'),\n",
       " (u'Research', 'NNP'),\n",
       " (u'Institute', 'NNP'),\n",
       " (u',', ','),\n",
       " (u'Joseph', 'NNP'),\n",
       " (u'Perez', 'NNP'),\n",
       " (u',', ','),\n",
       " (u'Auburn', 'NNP'),\n",
       " (u'University', 'NNP')]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize, word_tokenize, pos_tag, ne_chunk\n",
    "from nameparser.parser import HumanName\n",
    "from pprint import pprint\n",
    "\n",
    "def get_human_names(text):\n",
    "    tokens = nltk.tokenize.word_tokenize(text)\n",
    "    pos = nltk.pos_tag(tokens)\n",
    "    sentt = nltk.ne_chunk(pos, binary = False)\n",
    "    person_list = []\n",
    "    person = []\n",
    "    name = \"\"\n",
    "    for subtree in sentt.subtrees(filter=lambda t: t.node == 'PERSON'):\n",
    "        for leaf in subtree.leaves():\n",
    "            person.append(leaf[0])\n",
    "        if len(person) > 1: #avoid grabbing lone surnames\n",
    "            for part in person:\n",
    "                name += part + ' '\n",
    "            if name[:-1] not in person_list:\n",
    "                person_list.append(name[:-1])\n",
    "            name = ''\n",
    "        person = []\n",
    "\n",
    "    return (person_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from genderizer.genderizer import Genderizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'Philip', u'PERSON')\n",
      "(u'Valek', u'PERSON')\n",
      "(u'Natalia', u'PERSON')\n",
      "(u'Buzulukova', u'PERSON')\n",
      "(u'Jerry', u'PERSON')\n",
      "(u'Goldstein', u'PERSON')\n",
      "(u'Amy', u'PERSON')\n",
      "(u'Keesee', u'PERSON')\n",
      "(u'David', u'PERSON')\n",
      "(u'McComas', u'PERSON')\n",
      "(u'Joseph', u'PERSON')\n",
      "(u'Perez', u'PERSON')\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tag.stanford import StanfordNERTagger as NERTagger\n",
    "st = NERTagger('classifiers/english.all.3class.distsim.crf.ser.gz', 'stanford-ner.jar')\n",
    "text = ', '.join(authors[0].split('\\n'))\n",
    "\n",
    "for sent in nltk.sent_tokenize(text):\n",
    "    tokens = nltk.tokenize.word_tokenize(sent)\n",
    "    tags = st.tag(tokens)\n",
    "    for tag in tags:\n",
    "        if tag[1]=='PERSON': \n",
    "            print tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Authors', u'O'),\n",
       " (u'Philip', u'ORGANIZATION'),\n",
       " (u'Valek', u'ORGANIZATION'),\n",
       " (u'University', u'ORGANIZATION'),\n",
       " (u'of', u'ORGANIZATION'),\n",
       " (u'Texas', u'ORGANIZATION'),\n",
       " (u'at', u'O'),\n",
       " (u'San', u'ORGANIZATION'),\n",
       " (u'Antonio', u'ORGANIZATION'),\n",
       " (u'Southwest', u'ORGANIZATION'),\n",
       " (u'Research', u'ORGANIZATION'),\n",
       " (u'Institute', u'ORGANIZATION'),\n",
       " (u'Natalia', u'ORGANIZATION'),\n",
       " (u'Buzulukova', u'ORGANIZATION'),\n",
       " (u'NASA', u'ORGANIZATION'),\n",
       " (u'Goddard', u'O')]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_nertagger.tag(authors[0].split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Rami', u'PERSON'),\n",
       " (u'Eid', u'PERSON'),\n",
       " (u'is', u'O'),\n",
       " (u'studying', u'O'),\n",
       " (u'at', u'O'),\n",
       " (u'Stony', u'ORGANIZATION'),\n",
       " (u'Brook', u'ORGANIZATION'),\n",
       " (u'University', u'ORGANIZATION'),\n",
       " (u'in', u'O'),\n",
       " (u'NY', u'O')]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_nertagger.tag('Rami Eid is studying at Stony Brook University in NY'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rami',\n",
       " 'Eid',\n",
       " 'is',\n",
       " 'studying',\n",
       " 'at',\n",
       " 'Stony',\n",
       " 'Brook',\n",
       " 'University',\n",
       " 'in',\n",
       " 'NY']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Rami Eid is studying at Stony Brook University in NY'.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print Genderizer.detect(firstName = 'marie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
